{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ff139a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import struct\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.common.exceptions import TimeoutException, StaleElementReferenceException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b515c4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Disable oneDNN in TensorFlow to avoid numerical errors\n",
    "os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4d02cd",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class SmartTraderPredictor:\n",
    "    def __init__(self, historical_data_path):\n",
    "        print(\"Iniciando SmartTraderPredictor...\")\n",
    "        self.historical_data_path = historical_data_path\n",
    "        self.driver = None\n",
    "        self.last_number = None\n",
    "        self.historical_digits = []\n",
    "        self.lstm_model = None\n",
    "        self.rf_model = None\n",
    "        self.xgb_model = None\n",
    "        self.ensemble_model = None\n",
    "        self.service = Service(ChromeDriverManager().install())\n",
    "        self.setup_logging()\n",
    "\n",
    "    def setup_logging(self):\n",
    "        logging.basicConfig(filename='smarttrader_predictor.log', level=logging.INFO,\n",
    "                            format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "        console = logging.StreamHandler()\n",
    "        console.setLevel(logging.INFO)\n",
    "        logging.getLogger('').addHandler(console)\n",
    "\n",
    "    def setup_driver(self):\n",
    "        try:\n",
    "            options = webdriver.ChromeOptions()\n",
    "            options.add_argument('--headless')\n",
    "            options.add_argument('--disable-gpu')\n",
    "            options.add_argument('--no-sandbox')\n",
    "            options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "            self.driver = webdriver.Chrome(service=self.service, options=options)\n",
    "            self.driver.get('https://smarttrader.deriv.com/es/trading?currency=USD&market=synthetics&underlying=R_100&formname=matchdiff&duration_amount=1&duration_units=t&amount=315&amount_type=stake&expiry_type=duration&multiplier=1&prediction=8')\n",
    "            logging.info(\"WebDriver initialized successfully\")\n",
    "            print(\"WebDriver configurado correctamente\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error initializing WebDriver: {e}\")\n",
    "            print(f\"Error inicializando WebDriver: {e}\")\n",
    "            raise\n",
    "\n",
    "    def read_historical_data(self):\n",
    "        data = []\n",
    "        count = 0\n",
    "\n",
    "        def process_chunk(chunk):\n",
    "            local_data = []\n",
    "            local_count = 0\n",
    "            for line in chunk:\n",
    "                if \"Número capturado\" in line:\n",
    "                    try:\n",
    "                        number_str = line.split(\" - \")[0].replace(\"Número capturado: \", \"\").strip().replace(\".\", \"\")\n",
    "                        if re.match(r'^\\d+$', number_str):\n",
    "                            local_data.append(int(number_str))\n",
    "                            local_count += 1\n",
    "                    except (ValueError, IndexError) as e:\n",
    "                        logging.error(f\"Error parsing line: {line.strip()}. Error: {e}\")\n",
    "                        print(f\"Error parseando línea: {line.strip()}. Error: {e}\")\n",
    "            return local_data, local_count\n",
    "\n",
    "        try:\n",
    "            print(\"Leyendo datos históricos...\")\n",
    "            \n",
    "            chunk_size = 100000\n",
    "            with open(self.historical_data_path, 'r', buffering=10**7) as file:\n",
    "                while chunk := list(file.readlines(chunk_size)):\n",
    "                    with ThreadPoolExecutor() as executor:\n",
    "                        results = list(executor.map(process_chunk, [chunk]))\n",
    "                    for local_data, local_count in results:\n",
    "                        data.extend(local_data)\n",
    "                        count += local_count\n",
    "\n",
    "            logging.info(f\"Total historical numbers read: {len(data)}\")\n",
    "            logging.info(f\"Total lines processed: {count}\")\n",
    "            print(f\"Total de números históricos leídos: {len(data)}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error reading historical data: {e}\")\n",
    "            print(f\"Error leyendo datos históricos: {e}\")\n",
    "        return data\n",
    "\n",
    "    def build_lstm_model(self, input_shape):\n",
    "        model = Sequential([\n",
    "            LSTM(4, activation='relu', input_shape=input_shape, return_sequences=True),\n",
    "            BatchNormalization(),\n",
    "            Dropout(0.2),\n",
    "            LSTM(2, activation='relu', return_sequences=False),\n",
    "            BatchNormalization(),\n",
    "            Dropout(0.2),\n",
    "            Dense(4, activation='relu'),\n",
    "            Dense(1)  # Cambiado a 1 salida para regresión\n",
    "        ])\n",
    "        model.compile(optimizer='adam', loss='mse', metrics=['mae'])  # Cambiado loss y metrics para regresión\n",
    "        return model\n",
    "\n",
    "    def optimize_random_forest(self, X, y):\n",
    "        param_grid = {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'max_depth': [None, 20, 30],\n",
    "            'min_samples_split': [2, 5],\n",
    "            'min_samples_leaf': [1, 2]\n",
    "        }\n",
    "        rf = RandomForestRegressor()\n",
    "        grid_search = GridSearchCV(rf, param_grid, cv=5, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "        grid_search.fit(X, y)\n",
    "        return grid_search.best_estimator_\n",
    "\n",
    "    def ensemble_models(self, X, y):\n",
    "        try:\n",
    "            print(\"Realizando predicciones con LSTM...\")\n",
    "            lstm_pred = self.lstm_model.predict(X)\n",
    "            print(\"Predicción con LSTM completada.\")\n",
    "            print(\"Realizando predicciones con Random Forest...\")\n",
    "            rf_pred = self.rf_model.predict(X).reshape(-1, 1)\n",
    "            print(\"Predicción con Random Forest completada.\")\n",
    "            print(\"Realizando predicciones con XGBoost...\")\n",
    "            xgb_pred = self.xgb_model.predict(X).reshape(-1, 1)\n",
    "            print(\"Predicción con XGBoost completada.\")\n",
    "            print(\"Ensamblando resultados...\")\n",
    "            combined_pred = np.hstack((lstm_pred, rf_pred, xgb_pred))\n",
    "            meta_model = LinearRegression()\n",
    "            meta_model.fit(combined_pred, y)\n",
    "            print(\"Ensamblaje completado.\")\n",
    "            return meta_model\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error during model ensembling: {e}\")\n",
    "        print(f\"Error durante el ensamblaje de modelos: {e}\")\n",
    "\n",
    "    def validate_model(self, model, X, y):\n",
    "        scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "        mse_scores = -scores  # Convertir a MSE positivo\n",
    "        rmse_scores = np.sqrt(mse_scores)\n",
    "        logging.info(f\"Cross-validation RMSE: {np.mean(rmse_scores)}\")\n",
    "        print(f\"RMSE de validación cruzada: {np.mean(rmse_scores)}\")\n",
    "\n",
    "    def prepare_sequence_data(self, data, sequence_length):\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        data = scaler.fit_transform(np.array(data).reshape(-1, 1))\n",
    "        X, y = [], []\n",
    "        for i in range(len(data) - sequence_length):\n",
    "            X.append(data[i:i + sequence_length])\n",
    "            y.append(data[i + sequence_length])\n",
    "        return np.array(X), np.array(y).ravel()  # Flatten y\n",
    "\n",
    "    def train_models(self):\n",
    "        print(\"Entrenando modelos...\")\n",
    "        self.historical_digits = self.read_historical_data()\n",
    "\n",
    "        if len(self.historical_digits) < 100:\n",
    "            logging.warning(\"No hay suficientes datos históricos para entrenar los modelos\")\n",
    "            print(\"No hay suficientes datos históricos para entrenar los modelos\")\n",
    "            return\n",
    "\n",
    "        sequence_length = 50\n",
    "        X, y = self.prepare_sequence_data(self.historical_digits, sequence_length)\n",
    "\n",
    "        # LSTM model\n",
    "        input_shape = (X.shape[1], 1)\n",
    "        self.lstm_model = self.build_lstm_model(input_shape)\n",
    "        self.lstm_model.fit(X, y, epochs=1, batch_size=128, validation_split=0.1, callbacks=[EarlyStopping(patience=3)])\n",
    "\n",
    "        # Random Forest model\n",
    "        X_2d = X.reshape(X.shape[0], -1)\n",
    "        self.rf_model = self.optimize_random_forest(X_2d, y)\n",
    "\n",
    "        # XGBoost model\n",
    "        self.xgb_model = XGBRegressor()\n",
    "        self.xgb_model.fit(X_2d, y)\n",
    "\n",
    "        # Ensemble model\n",
    "        self.ensemble_model = self.ensemble_models(X, y)\n",
    "        self.validate_model(self.ensemble_model, X_2d, y)\n",
    "\n",
    "        logging.info(\"Entrenamiento de modelos completado.\")\n",
    "        print(\"Entrenamiento completado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f57fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una instancia del predictor y entrenar los modelos\n",
    "smart_trader_predictor = SmartTraderPredictor('D:/Escritorio/cinta holografica/reporte_numeros.txt')\n",
    "smart_trader_predictor.setup_driver()\n",
    "smart_trader_predictor.train_models()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
